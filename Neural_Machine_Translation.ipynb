{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e121acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "10aae25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f69fa163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c6b956d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bc7083b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>This percentage is even greater than the perce...</td>\n",
       "      <td>यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indic2012</td>\n",
       "      <td>.The ending portion of these Vedas is called U...</td>\n",
       "      <td>इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                                   english_sentence  \\\n",
       "0        ted  politicians do not have permission to do what ...   \n",
       "1        ted         I'd like to tell you about one such child,   \n",
       "2  indic2012  This percentage is even greater than the perce...   \n",
       "3        ted  what we really mean is that they're bad at not...   \n",
       "4  indic2012  .The ending portion of these Vedas is called U...   \n",
       "\n",
       "                                      hindi_sentence  \n",
       "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
       "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "74451f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tides        50000\n",
       "ted          39881\n",
       "indic2012    37726\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f22eb16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ted</td>\n",
       "      <td>politicians do not have permission to do what ...</td>\n",
       "      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ted</td>\n",
       "      <td>I'd like to tell you about one such child,</td>\n",
       "      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ted</td>\n",
       "      <td>what we really mean is that they're bad at not...</td>\n",
       "      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ted</td>\n",
       "      <td>And who are we to say, even, that they are wrong</td>\n",
       "      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ted</td>\n",
       "      <td>So there is some sort of justice</td>\n",
       "      <td>तो वहाँ न्याय है</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source                                   english_sentence  \\\n",
       "0     ted  politicians do not have permission to do what ...   \n",
       "1     ted         I'd like to tell you about one such child,   \n",
       "3     ted  what we really mean is that they're bad at not...   \n",
       "7     ted   And who are we to say, even, that they are wrong   \n",
       "13    ted                   So there is some sort of justice   \n",
       "\n",
       "                                       hindi_sentence  \n",
       "0   राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
       "1   मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
       "3      हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
       "7    और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं  \n",
       "13                                   तो वहाँ न्याय है  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df[df['source']=='ted']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cb634945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source              0\n",
       "english_sentence    0\n",
       "hindi_sentence      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(df).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a1887172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~pd.isnull(df['english_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c3eae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5471f3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.sample(n=25000,random_state=42)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fa858d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['english_sentence']=df['english_sentence'].apply(lambda x: x.lower())\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c95a2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f96f9397",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_punct=set(string.punctuation)\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in exclude_punct))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x:''.join(ch for ch in x if ch not in exclude_punct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9cabf872",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_digits = str.maketrans('', '', digits)\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: x.strip())\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: x.strip())\n",
    "df['english_sentence']=df['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "df['hindi_sentence']=df['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4efeb21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hindi_sentence'] = df['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b9325511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate cli...</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "82040     ted  we still dont know who her parents are who she is   \n",
       "85038     ted                                        no keyboard   \n",
       "58018     ted                    but as far as being a performer   \n",
       "74470     ted                        and this particular balloon   \n",
       "122330    ted  and its not as hard as you think integrate cli...   \n",
       "\n",
       "                                           hindi_sentence  \n",
       "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...  \n",
       "85038                       START_ कोई कुंजीपटल नहीं _END  \n",
       "58018             START_ लेकिन एक कलाकार होने के साथ _END  \n",
       "74470                      START_ और यह खास गुब्बारा _END  \n",
       "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f9813cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get English and Hindi Vocabulary\n",
    "all_eng_words=set()\n",
    "for eng in df['english_sentence']:\n",
    "    for word in eng.split():\n",
    "        if word not in all_eng_words:\n",
    "            all_eng_words.add(word)\n",
    "\n",
    "all_hindi_words=set()\n",
    "for hin in df['hindi_sentence']:\n",
    "    for word in hin.split():\n",
    "        if word not in all_hindi_words:\n",
    "            all_hindi_words.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "dfdc7123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14030"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_eng_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "3781b691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17540"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_hindi_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4eb39343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length_eng_sentence']=df['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
    "df['length_hin_sentence']=df['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "74192b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82040</th>\n",
       "      <td>ted</td>\n",
       "      <td>we still dont know who her parents are who she is</td>\n",
       "      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85038</th>\n",
       "      <td>ted</td>\n",
       "      <td>no keyboard</td>\n",
       "      <td>START_ कोई कुंजीपटल नहीं _END</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58018</th>\n",
       "      <td>ted</td>\n",
       "      <td>but as far as being a performer</td>\n",
       "      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74470</th>\n",
       "      <td>ted</td>\n",
       "      <td>and this particular balloon</td>\n",
       "      <td>START_ और यह खास गुब्बारा _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122330</th>\n",
       "      <td>ted</td>\n",
       "      <td>and its not as hard as you think integrate cli...</td>\n",
       "      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं...</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "82040     ted  we still dont know who her parents are who she is   \n",
       "85038     ted                                        no keyboard   \n",
       "58018     ted                    but as far as being a performer   \n",
       "74470     ted                        and this particular balloon   \n",
       "122330    ted  and its not as hard as you think integrate cli...   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "82040   START_ हम अभी तक नहीं जानते हैं कि उसके मातापि...   \n",
       "85038                       START_ कोई कुंजीपटल नहीं _END   \n",
       "58018             START_ लेकिन एक कलाकार होने के साथ _END   \n",
       "74470                      START_ और यह खास गुब्बारा _END   \n",
       "122330  START_ और जितना आपको लगता है यह उतना कठिन नहीं...   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "82040                    11                   16  \n",
       "85038                     2                    5  \n",
       "58018                     7                    8  \n",
       "74470                     4                    6  \n",
       "122330                   16                   20  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aa327873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['length_eng_sentence']>30].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7baadfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['length_eng_sentence']<=20]\n",
    "df=df[df['length_hin_sentence']<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "56b96fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24774, 5)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "307e729c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of Hindi Sentence  20\n",
      "maximum length of English Sentence  20\n"
     ]
    }
   ],
   "source": [
    "print(\"maximum length of Hindi Sentence \",max(df['length_hin_sentence']))\n",
    "print(\"maximum length of English Sentence \",max(df['length_eng_sentence']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3030a1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_src=max(df['length_eng_sentence'])\n",
    "max_length_tar=max(df['length_hin_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "6b60625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14030, 17540)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_eng_words))\n",
    "target_words = sorted(list(all_hindi_words))\n",
    "num_encoder_tokens = len(all_eng_words)\n",
    "num_decoder_tokens = len(all_hindi_words)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3c92560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_decoder_tokens = num_decoder_tokens + 1 #for zero padding\n",
    "num_encoder_tokens = num_encoder_tokens + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a7775ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "64bfc4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "277a5e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "707ea1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>english_sentence</th>\n",
       "      <th>hindi_sentence</th>\n",
       "      <th>length_eng_sentence</th>\n",
       "      <th>length_hin_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55399</th>\n",
       "      <td>ted</td>\n",
       "      <td>now i had an amazing experience i was years old</td>\n",
       "      <td>START_ अब मुझे एक अदभुत अनुभव हुआ मैं साल का थ...</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92180</th>\n",
       "      <td>ted</td>\n",
       "      <td>the whole country went mad</td>\n",
       "      <td>START_ पूरा देश ही उथलपुथल में था। _END</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45268</th>\n",
       "      <td>ted</td>\n",
       "      <td>in fact if the world were just filled with com...</td>\n",
       "      <td>START_ वास्तव में यदि संसार मात्र करुणा से भरा...</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16544</th>\n",
       "      <td>ted</td>\n",
       "      <td>thanking us for the valiant effort displayed</td>\n",
       "      <td>START_ प्रदर्शन के लिए आभार प्रगट करने के लिए ...</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52090</th>\n",
       "      <td>ted</td>\n",
       "      <td>that is all about execution all about the howto</td>\n",
       "      <td>START_ जो कि गरजने के बजाय बरसने का अध्याय है ...</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77007</th>\n",
       "      <td>ted</td>\n",
       "      <td>then you get to their political articles</td>\n",
       "      <td>START_ अब इनके राजनैतिक लेख देखिये। _END</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109851</th>\n",
       "      <td>ted</td>\n",
       "      <td>they didnt care about it</td>\n",
       "      <td>START_ उन्हें इश बात की पर्व नहीं थी _END</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80472</th>\n",
       "      <td>ted</td>\n",
       "      <td>as simple as possible but no simpler</td>\n",
       "      <td>START_ को जितना हो सके आसान बनाये लेकिन साधारण...</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30257</th>\n",
       "      <td>ted</td>\n",
       "      <td>and so amitabha decided that he would take tha...</td>\n",
       "      <td>START_ और इसलिये अमिताभ ने फ़ैसला किया कि वो इ...</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62747</th>\n",
       "      <td>ted</td>\n",
       "      <td>a wellwisher of mine</td>\n",
       "      <td>START_ मेरा भला चाहने वाली _END</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source                                   english_sentence  \\\n",
       "55399     ted    now i had an amazing experience i was years old   \n",
       "92180     ted                         the whole country went mad   \n",
       "45268     ted  in fact if the world were just filled with com...   \n",
       "16544     ted       thanking us for the valiant effort displayed   \n",
       "52090     ted    that is all about execution all about the howto   \n",
       "77007     ted           then you get to their political articles   \n",
       "109851    ted                           they didnt care about it   \n",
       "80472     ted               as simple as possible but no simpler   \n",
       "30257     ted  and so amitabha decided that he would take tha...   \n",
       "62747     ted                               a wellwisher of mine   \n",
       "\n",
       "                                           hindi_sentence  \\\n",
       "55399   START_ अब मुझे एक अदभुत अनुभव हुआ मैं साल का थ...   \n",
       "92180             START_ पूरा देश ही उथलपुथल में था। _END   \n",
       "45268   START_ वास्तव में यदि संसार मात्र करुणा से भरा...   \n",
       "16544   START_ प्रदर्शन के लिए आभार प्रगट करने के लिए ...   \n",
       "52090   START_ जो कि गरजने के बजाय बरसने का अध्याय है ...   \n",
       "77007            START_ अब इनके राजनैतिक लेख देखिये। _END   \n",
       "109851          START_ उन्हें इश बात की पर्व नहीं थी _END   \n",
       "80472   START_ को जितना हो सके आसान बनाये लेकिन साधारण...   \n",
       "30257   START_ और इसलिये अमिताभ ने फ़ैसला किया कि वो इ...   \n",
       "62747                     START_ मेरा भला चाहने वाली _END   \n",
       "\n",
       "        length_eng_sentence  length_hin_sentence  \n",
       "55399                    10                   12  \n",
       "92180                     5                    8  \n",
       "45268                    10                   11  \n",
       "16544                     7                   12  \n",
       "52090                     9                   19  \n",
       "77007                     7                    7  \n",
       "109851                    5                    9  \n",
       "80472                     7                   11  \n",
       "30257                    10                   13  \n",
       "62747                     4                    6  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fc9df8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19819,), (4955,), (19819,), (4955,))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df['english_sentence'], df['hindi_sentence']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
    "X_train.shape, X_test.shape,y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0696a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c53e0718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                for t, word in enumerate(input_text.split()):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a15fc661",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bbca830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "594ca93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8a0b9420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, None, 300)            4209300   ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, None, 300)            5262300   ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               [(None, 300),                721200    ['embedding_6[0][0]']         \n",
      "                              (None, 300),                                                        \n",
      "                              (None, 300)]                                                        \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               [(None, None, 300),          721200    ['embedding_7[0][0]',         \n",
      "                              (None, 300),                           'lstm_6[0][1]',              \n",
      "                              (None, 300)]                           'lstm_6[0][2]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, None, 17541)          5279841   ['lstm_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16193841 (61.77 MB)\n",
      "Trainable params: 16193841 (61.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "29f6659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "adam = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "05379525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_6 (Embedding)     (None, None, 300)            4209300   ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)     (None, None, 300)            5262300   ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_6 (LSTM)               [(None, 300),                721200    ['embedding_6[0][0]']         \n",
      "                              (None, 300),                                                        \n",
      "                              (None, 300)]                                                        \n",
      "                                                                                                  \n",
      " lstm_7 (LSTM)               [(None, None, 300),          721200    ['embedding_7[0][0]',         \n",
      "                              (None, 300),                           'lstm_6[0][1]',              \n",
      "                              (None, 300)]                           'lstm_6[0][2]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, None, 17541)          5279841   ['lstm_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 16193841 (61.77 MB)\n",
      "Trainable params: 16193841 (61.77 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "becf9810",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "4bddf131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "154/154 [==============================] - 175s 1s/step - loss: 6.8068\n",
      "Epoch 2/100\n",
      "154/154 [==============================] - 164s 1s/step - loss: 6.0136\n",
      "Epoch 3/100\n",
      "154/154 [==============================] - 162s 1s/step - loss: 5.6594\n",
      "Epoch 4/100\n",
      "154/154 [==============================] - 164s 1s/step - loss: 5.4206\n",
      "Epoch 5/100\n",
      "154/154 [==============================] - 163s 1s/step - loss: 5.2284\n",
      "Epoch 6/100\n",
      "154/154 [==============================] - 166s 1s/step - loss: 5.0465\n",
      "Epoch 7/100\n",
      "154/154 [==============================] - 162s 1s/step - loss: 4.8729\n",
      "Epoch 8/100\n",
      "154/154 [==============================] - 178s 1s/step - loss: 4.7081\n",
      "Epoch 9/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 4.5479\n",
      "Epoch 10/100\n",
      "154/154 [==============================] - 201s 1s/step - loss: 4.3898\n",
      "Epoch 11/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 4.2320\n",
      "Epoch 12/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 4.0800\n",
      "Epoch 13/100\n",
      "154/154 [==============================] - 201s 1s/step - loss: 3.9246\n",
      "Epoch 14/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 3.7698\n",
      "Epoch 15/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 3.6209\n",
      "Epoch 16/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 3.4719\n",
      "Epoch 17/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 3.3273\n",
      "Epoch 18/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 3.1873\n",
      "Epoch 19/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 3.0433\n",
      "Epoch 20/100\n",
      "154/154 [==============================] - 197s 1s/step - loss: 2.9041\n",
      "Epoch 21/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 2.7711\n",
      "Epoch 22/100\n",
      "154/154 [==============================] - 199s 1s/step - loss: 2.6479\n",
      "Epoch 23/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 2.5276\n",
      "Epoch 24/100\n",
      "154/154 [==============================] - 200s 1s/step - loss: 2.4068\n",
      "Epoch 25/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 2.2898\n",
      "Epoch 26/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 2.1804\n",
      "Epoch 27/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 2.0792\n",
      "Epoch 28/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.9811\n",
      "Epoch 29/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.8887\n",
      "Epoch 30/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.7991\n",
      "Epoch 31/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.7010\n",
      "Epoch 32/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.6074\n",
      "Epoch 33/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.5194\n",
      "Epoch 34/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.4343\n",
      "Epoch 35/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.3578\n",
      "Epoch 36/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.2869\n",
      "Epoch 37/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.2131\n",
      "Epoch 38/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.1468\n",
      "Epoch 39/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.0827\n",
      "Epoch 40/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 1.0176\n",
      "Epoch 41/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.9634\n",
      "Epoch 42/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.9094\n",
      "Epoch 43/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.8570\n",
      "Epoch 44/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.8014\n",
      "Epoch 45/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.7421\n",
      "Epoch 46/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.6914\n",
      "Epoch 47/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.6456\n",
      "Epoch 48/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.6036\n",
      "Epoch 49/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.5616\n",
      "Epoch 50/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.5227\n",
      "Epoch 51/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.4874\n",
      "Epoch 52/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.4519\n",
      "Epoch 53/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.4183\n",
      "Epoch 54/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.3854\n",
      "Epoch 55/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.3603\n",
      "Epoch 56/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.3356\n",
      "Epoch 57/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.3114\n",
      "Epoch 58/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.2881\n",
      "Epoch 59/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.2649\n",
      "Epoch 60/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.2415\n",
      "Epoch 61/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.2192\n",
      "Epoch 62/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.1979\n",
      "Epoch 63/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.1794\n",
      "Epoch 64/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.1643\n",
      "Epoch 65/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.1516\n",
      "Epoch 66/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.1390\n",
      "Epoch 67/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.1279\n",
      "Epoch 68/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.1189\n",
      "Epoch 69/100\n",
      "154/154 [==============================] - 199s 1s/step - loss: 0.1110\n",
      "Epoch 70/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.1031\n",
      "Epoch 71/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0944\n",
      "Epoch 72/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0900\n",
      "Epoch 73/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0861\n",
      "Epoch 74/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0832\n",
      "Epoch 75/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0753\n",
      "Epoch 76/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0667\n",
      "Epoch 77/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0567\n",
      "Epoch 78/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0486\n",
      "Epoch 79/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0422\n",
      "Epoch 80/100\n",
      "154/154 [==============================] - 210s 1s/step - loss: 0.0374\n",
      "Epoch 81/100\n",
      "154/154 [==============================] - 211s 1s/step - loss: 0.0333\n",
      "Epoch 82/100\n",
      "154/154 [==============================] - 210s 1s/step - loss: 0.0300\n",
      "Epoch 83/100\n",
      "154/154 [==============================] - 210s 1s/step - loss: 0.0273\n",
      "Epoch 84/100\n",
      "154/154 [==============================] - 214s 1s/step - loss: 0.0256\n",
      "Epoch 85/100\n",
      "154/154 [==============================] - 198s 1s/step - loss: 0.0248\n",
      "Epoch 86/100\n",
      "154/154 [==============================] - 210s 1s/step - loss: 0.0249\n",
      "Epoch 87/100\n",
      "154/154 [==============================] - 202s 1s/step - loss: 0.0252\n",
      "Epoch 88/100\n",
      "154/154 [==============================] - 202s 1s/step - loss: 0.0257\n",
      "Epoch 89/100\n",
      "154/154 [==============================] - 199s 1s/step - loss: 0.0282\n",
      "Epoch 90/100\n",
      "154/154 [==============================] - 199s 1s/step - loss: 0.0327\n",
      "Epoch 91/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 0.0395\n",
      "Epoch 92/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 0.0469\n",
      "Epoch 93/100\n",
      "154/154 [==============================] - 199s 1s/step - loss: 0.0516\n",
      "Epoch 94/100\n",
      "154/154 [==============================] - 201s 1s/step - loss: 0.0473\n",
      "Epoch 95/100\n",
      "154/154 [==============================] - 219s 1s/step - loss: 0.0354\n",
      "Epoch 96/100\n",
      "154/154 [==============================] - 199s 1s/step - loss: 0.0244\n",
      "Epoch 97/100\n",
      "154/154 [==============================] - 201s 1s/step - loss: 0.0176\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/154 [==============================] - 203s 1s/step - loss: 0.0135\n",
      "Epoch 99/100\n",
      "154/154 [==============================] - 196s 1s/step - loss: 0.0112\n",
      "Epoch 100/100\n",
      "154/154 [==============================] - 207s 1s/step - loss: 0.0098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1fdc6ac0700>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    generate_batch(X_train, y_train, batch_size),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "400b66c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "31f1fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the \"thought vectors\"\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
    "\n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs2] + decoder_states2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "89bdd356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = target_token_index['START_']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '_END' or\n",
    "           len(decoded_sentence) > 50):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "307150c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
    "k=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "b3f2be52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Input English sentence: by the summer in the middle of the general campaign\n",
      "Actual Hindi Translation:  गर्मीयों तक आम चुनाव प्रचार के बीच में \n",
      "Predicted Hindi Translation:  गर्मीयों तक आम चुनाव प्रचार के बीच में \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "eacd7a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Input English sentence: to conceal a secret within its seams or something\n",
      "Actual Hindi Translation:  अपने सिलाई के भीतर एक राज़ छुपाने की या और कुछ \n",
      "Predicted Hindi Translation:  अपने सिलाई के भीतर एक राज़ छुपाने की या और कुछ \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "69535e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Input English sentence: but i very much appreciate\n",
      "Actual Hindi Translation:  पर मैं उसका बहुत आभारी हूँ कि \n",
      "Predicted Hindi Translation:  पर मैं उसका बहुत आभारी हूँ कि \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "10d377dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Input English sentence: to experience what it means to be a child laborer\n",
      "Actual Hindi Translation:  ताकि वे अनुभव कर सकें कि बाल श्रमिक होना क्या होता है \n",
      "Predicted Hindi Translation:  ताकि वे अनुभव कर सकें कि बाल श्रमिक होना क्या \n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "1d3c5fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "Input English sentence: my friend chris who i just showed you a picture of\n",
      "Actual Hindi Translation:  मेरा दोस्त क्रिस जिसके साथ खींची फोटो मैंने आपको अभी दिखाई थी \n",
      "Predicted Hindi Translation:  मेरा दोस्त क्रिस जिसके साथ खींची फोटो मैंने आपको\n"
     ]
    }
   ],
   "source": [
    "k+=1\n",
    "(input_seq, actual_output), _ = next(train_gen)\n",
    "decoded_sentence = decode_sequence(input_seq)\n",
    "print('Input English sentence:', X_train[k:k+1].values[0])\n",
    "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
    "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943afba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
